#!/usr/bin/env python3
"""
5M Baseline Analysis - v3.0_05M Comprehensive Analysis with 15M Comparison
============================================================================
Analyzes NAS100 5-minute timeframe baseline performance and compares against 15M baseline.
Expected findings:
- ~1,500-2,000 trades (4.4x more than 15M's 454)
- ~50,000 signals (12x more than 15M's 17,477)
- Baseline WR ~25-30% (similar to 15M's 28%)
- Zone/Regime patterns should align, but hourly patterns may differ (5M more granular)
"""

import pandas as pd
import numpy as np
from datetime import datetime

print("="*80)
print("5M BASELINE ANALYSIS - v3.0_05M with 15M Comparison")
print("="*80)

# ============================================================================
# LOAD 5M DATA
# ============================================================================
print("\nüìÅ Loading 5M baseline data...")
trades_file = 'TP_Integrated_Trades_NAS100_v3.0_05M.csv'
signals_file = 'TP_Integrated_Signals_NAS100_v3.0_05M.csv'
mt5_file = 'MTBacktest_Report_3.0_05M.csv'

df_trades = pd.read_csv(trades_file)
df_signals = pd.read_csv(signals_file)
df_mt5 = pd.read_csv(mt5_file)

print(f"   Trades loaded: {len(df_trades):,}")
print(f"   Signals loaded: {len(df_signals):,}")
print(f"   MT5 deals loaded: {len(df_mt5):,}")

# Parse timestamps
df_trades['EntryTime'] = pd.to_datetime(df_trades['EntryTime'])
df_trades['ExitTime'] = pd.to_datetime(df_trades['ExitTime'])
df_signals['BarTime'] = pd.to_datetime(df_signals['BarTime'])

# Extract temporal features
df_trades['Hour'] = df_trades['EntryTime'].dt.hour
df_trades['DayOfWeek'] = df_trades['EntryTime'].dt.day_name()
df_trades['Date'] = df_trades['EntryTime'].dt.date

# ============================================================================
# 15M BASELINE REFERENCE METRICS (for comparison)
# ============================================================================
print("\n" + "="*80)
print("15M BASELINE REFERENCE METRICS")
print("="*80)
ref_15m = {
    'trades': 454,
    'win_rate': 28.0,
    'profit_factor': 0.97,
    'net_pnl': -6.97,
    'avg_rr': 2.50,
    'winners': 127,
    'losers': 327,
    'signals': 17477,
    'test_days': 267,
    'worst_zone': 'BEAR',
    'worst_zone_wr': 19.0,
    'worst_regime': 'LOW',
    'worst_regime_wr': 21.2,
    'worst_hour': 8,
    'worst_hour_wr': 11.8,
    'best_hour': 12,
    'best_hour_wr': 45.0
}

print(f"Trades: {ref_15m['trades']}")
print(f"Win Rate: {ref_15m['win_rate']:.1f}%")
print(f"Profit Factor: {ref_15m['profit_factor']:.2f}")
print(f"Net P&L: ${ref_15m['net_pnl']:.2f}")
print(f"Avg R:R: {ref_15m['avg_rr']:.2f}:1")
print(f"Signals: {ref_15m['signals']:,}")
print(f"Test Period: {ref_15m['test_days']} days")
print(f"Worst Zone: {ref_15m['worst_zone']} ({ref_15m['worst_zone_wr']:.1f}% WR)")
print(f"Worst Regime: {ref_15m['worst_regime']} ({ref_15m['worst_regime_wr']:.1f}% WR)")
print(f"Worst Hour: {ref_15m['worst_hour']} ({ref_15m['worst_hour_wr']:.1f}% WR)")
print(f"Best Hour: {ref_15m['best_hour']} ({ref_15m['best_hour_wr']:.1f}% WR)")

# ============================================================================
# 5M BASIC PERFORMANCE METRICS
# ============================================================================
print("\n" + "="*80)
print("5M BASELINE PERFORMANCE METRICS")
print("="*80)

total_trades = len(df_trades)
winners = df_trades[df_trades['NetProfit'] > 0]
losers = df_trades[df_trades['NetProfit'] < 0]

win_count = len(winners)
loss_count = len(losers)
win_rate = (win_count / total_trades * 100) if total_trades > 0 else 0

gross_profit = winners['NetProfit'].sum() if len(winners) > 0 else 0
gross_loss = abs(losers['NetProfit'].sum()) if len(losers) > 0 else 0
net_profit = df_trades['NetProfit'].sum()
profit_factor = (gross_profit / gross_loss) if gross_loss > 0 else 0

avg_win = winners['NetProfit'].mean() if len(winners) > 0 else 0
avg_loss = abs(losers['NetProfit'].mean()) if len(losers) > 0 else 0
avg_rr = (avg_win / avg_loss) if avg_loss > 0 else 0

# Test period analysis
start_date = df_trades['EntryTime'].min()
end_date = df_trades['ExitTime'].max()
test_days = (end_date - start_date).days

print(f"\nüìä OVERALL PERFORMANCE:")
print(f"   Total Trades: {total_trades:,}")
print(f"   Winners: {win_count} ({win_rate:.1f}%)")
print(f"   Losers: {loss_count} ({100-win_rate:.1f}%)")
print(f"   Win Rate: {win_rate:.1f}%")
print(f"   Profit Factor: {profit_factor:.2f}")
print(f"   Net P&L: ${net_profit:.2f}")
print(f"   Gross Profit: ${gross_profit:.2f}")
print(f"   Gross Loss: ${gross_loss:.2f}")
print(f"   Avg Win: ${avg_win:.2f}")
print(f"   Avg Loss: ${avg_loss:.2f}")
print(f"   Avg R:R Ratio: {avg_rr:.2f}:1")

print(f"\nüìÖ TEST PERIOD:")
print(f"   Start: {start_date.strftime('%Y-%m-%d %H:%M')}")
print(f"   End: {end_date.strftime('%Y-%m-%d %H:%M')}")
print(f"   Duration: {test_days} days")
print(f"   Trades/Day: {total_trades/test_days:.2f}")
print(f"   Total Signals: {len(df_signals):,}")
print(f"   Signal-to-Trade Ratio: {len(df_signals)/total_trades:.1f}:1")

# ============================================================================
# 5M vs 15M COMPARISON
# ============================================================================
print("\n" + "="*80)
print("5M vs 15M BASELINE COMPARISON")
print("="*80)

trade_ratio = total_trades / ref_15m['trades']
signal_ratio = len(df_signals) / ref_15m['signals']
wr_diff = win_rate - ref_15m['win_rate']
pf_diff = profit_factor - ref_15m['profit_factor']
pnl_diff = net_profit - ref_15m['net_pnl']

print(f"\nüìà SCALE COMPARISON:")
print(f"   5M Trades: {total_trades:,} vs 15M: {ref_15m['trades']} ({trade_ratio:.1f}x)")
print(f"   5M Signals: {len(df_signals):,} vs 15M: {ref_15m['signals']:,} ({signal_ratio:.1f}x)")
print(f"   5M has {trade_ratio:.1f}x more trades than 15M")
print(f"   5M has {signal_ratio:.1f}x more signals than 15M")
print(f"   Expected: ~3x (5M has 3x more bars per hour than 15M)")

print(f"\nüìä PERFORMANCE COMPARISON:")
print(f"   5M Win Rate: {win_rate:.1f}% vs 15M: {ref_15m['win_rate']:.1f}% ({wr_diff:+.1f}%)")
print(f"   5M Profit Factor: {profit_factor:.2f} vs 15M: {ref_15m['profit_factor']:.2f} ({pf_diff:+.2f})")
print(f"   5M Net P&L: ${net_profit:.2f} vs 15M: ${ref_15m['net_pnl']:.2f} ({pnl_diff:+.2f})")
print(f"   5M Avg R:R: {avg_rr:.2f}:1 vs 15M: {ref_15m['avg_rr']:.2f}:1")

if abs(wr_diff) < 5:
    print(f"   ‚úÖ Win rates similar (within 5%) - baseline quality consistent")
else:
    print(f"   ‚ö†Ô∏è  Win rates differ by {abs(wr_diff):.1f}% - timeframe affects entry quality")

# ============================================================================
# ZONE ANALYSIS
# ============================================================================
print("\n" + "="*80)
print("5M ZONE PERFORMANCE ANALYSIS")
print("="*80)

zone_performance = df_trades.groupby('Zone').agg({
    'TradeID': 'count',
    'NetProfit': ['sum', 'mean']
}).round(2)

zone_performance.columns = ['Trades', 'Total_PnL', 'Avg_PnL']

zone_winners = df_trades[df_trades['NetProfit'] > 0].groupby('Zone').size()
zone_wr = (zone_winners / df_trades.groupby('Zone').size() * 100).round(1)

zone_summary = pd.DataFrame({
    'Trades': zone_performance['Trades'],
    'WR%': zone_wr,
    'Total_PnL': zone_performance['Total_PnL'],
    'Avg_PnL': zone_performance['Avg_PnL']
}).sort_values('WR%')

print("\nüìä ZONE PERFORMANCE (sorted by Win Rate):")
print(zone_summary.to_string())

worst_zone_5m = zone_summary.index[0]
worst_zone_wr_5m = zone_summary.loc[worst_zone_5m, 'WR%']
best_zone_5m = zone_summary.iloc[-1].name
best_zone_wr_5m = zone_summary.loc[best_zone_5m, 'WR%']

print(f"\nüéØ KEY FINDINGS:")
print(f"   Worst Zone: {worst_zone_5m} ({worst_zone_wr_5m:.1f}% WR)")
print(f"   Best Zone: {best_zone_5m} ({best_zone_wr_5m:.1f}% WR)")
print(f"   Spread: {best_zone_wr_5m - worst_zone_wr_5m:.1f}%")

print(f"\nüîÑ COMPARISON TO 15M:")
print(f"   15M Worst: {ref_15m['worst_zone']} ({ref_15m['worst_zone_wr']:.1f}% WR)")
print(f"   5M Worst: {worst_zone_5m} ({worst_zone_wr_5m:.1f}% WR)")
if worst_zone_5m == ref_15m['worst_zone']:
    print(f"   ‚úÖ Same worst zone across timeframes - consistent pattern")
else:
    print(f"   ‚ö†Ô∏è  Different worst zones - timeframe-specific behavior")

# ============================================================================
# REGIME ANALYSIS
# ============================================================================
print("\n" + "="*80)
print("5M REGIME PERFORMANCE ANALYSIS")
print("="*80)

regime_performance = df_trades.groupby('Regime').agg({
    'TradeID': 'count',
    'NetProfit': ['sum', 'mean']
}).round(2)

regime_performance.columns = ['Trades', 'Total_PnL', 'Avg_PnL']

regime_winners = df_trades[df_trades['NetProfit'] > 0].groupby('Regime').size()
regime_wr = (regime_winners / df_trades.groupby('Regime').size() * 100).round(1)

regime_summary = pd.DataFrame({
    'Trades': regime_performance['Trades'],
    'WR%': regime_wr,
    'Total_PnL': regime_performance['Total_PnL'],
    'Avg_PnL': regime_performance['Avg_PnL']
}).sort_values('WR%')

print("\nüìä REGIME PERFORMANCE (sorted by Win Rate):")
print(regime_summary.to_string())

worst_regime_5m = regime_summary.index[0]
worst_regime_wr_5m = regime_summary.loc[worst_regime_5m, 'WR%']
best_regime_5m = regime_summary.iloc[-1].name
best_regime_wr_5m = regime_summary.loc[best_regime_5m, 'WR%']

print(f"\nüéØ KEY FINDINGS:")
print(f"   Worst Regime: {worst_regime_5m} ({worst_regime_wr_5m:.1f}% WR)")
print(f"   Best Regime: {best_regime_5m} ({best_regime_wr_5m:.1f}% WR)")
print(f"   Spread: {best_regime_wr_5m - worst_regime_wr_5m:.1f}%")

print(f"\nüîÑ COMPARISON TO 15M:")
print(f"   15M Worst: {ref_15m['worst_regime']} ({ref_15m['worst_regime_wr']:.1f}% WR)")
print(f"   5M Worst: {worst_regime_5m} ({worst_regime_wr_5m:.1f}% WR)")
if worst_regime_5m == ref_15m['worst_regime']:
    print(f"   ‚úÖ Same worst regime across timeframes - consistent pattern")
else:
    print(f"   ‚ö†Ô∏è  Different worst regimes - timeframe-specific behavior")

# ============================================================================
# HOURLY ANALYSIS
# ============================================================================
print("\n" + "="*80)
print("5M HOURLY PERFORMANCE ANALYSIS")
print("="*80)

hourly_performance = df_trades.groupby('Hour').agg({
    'TradeID': 'count',
    'NetProfit': ['sum', 'mean']
}).round(2)

hourly_performance.columns = ['Trades', 'Total_PnL', 'Avg_PnL']

hourly_winners = df_trades[df_trades['NetProfit'] > 0].groupby('Hour').size()
hourly_wr = (hourly_winners / df_trades.groupby('Hour').size() * 100).round(1)

hourly_summary = pd.DataFrame({
    'Trades': hourly_performance['Trades'],
    'WR%': hourly_wr,
    'Total_PnL': hourly_performance['Total_PnL'],
    'Avg_PnL': hourly_performance['Avg_PnL']
}).sort_values('WR%')

print("\nüìä HOURLY PERFORMANCE (sorted by Win Rate):")
print(hourly_summary.to_string())

worst_hour_5m = hourly_summary.index[0]
worst_hour_wr_5m = hourly_summary.loc[worst_hour_5m, 'WR%']
best_hour_5m = hourly_summary.iloc[-1].name
best_hour_wr_5m = hourly_summary.loc[best_hour_5m, 'WR%']

print(f"\nüéØ KEY FINDINGS:")
print(f"   Worst Hour: {worst_hour_5m} ({worst_hour_wr_5m:.1f}% WR)")
print(f"   Best Hour: {best_hour_5m} ({best_hour_wr_5m:.1f}% WR)")
print(f"   Spread: {best_hour_wr_5m - worst_hour_wr_5m:.1f}%")

print(f"\nüîÑ COMPARISON TO 15M:")
print(f"   15M Worst: Hour {ref_15m['worst_hour']} ({ref_15m['worst_hour_wr']:.1f}% WR)")
print(f"   5M Worst: Hour {worst_hour_5m} ({worst_hour_wr_5m:.1f}% WR)")
print(f"   15M Best: Hour {ref_15m['best_hour']} ({ref_15m['best_hour_wr']:.1f}% WR)")
print(f"   5M Best: Hour {best_hour_5m} ({best_hour_wr_5m:.1f}% WR)")

if worst_hour_5m == ref_15m['worst_hour'] and best_hour_5m == ref_15m['best_hour']:
    print(f"   ‚úÖ Same optimal hours across timeframes - consistent timing patterns")
else:
    print(f"   ‚ö†Ô∏è  Different optimal hours - 5M reveals intra-hour patterns 15M misses")

# ============================================================================
# PHYSICS METRICS CORRELATION ANALYSIS
# ============================================================================
print("\n" + "="*80)
print("5M PHYSICS METRICS CORRELATION ANALYSIS")
print("="*80)

# Calculate correlations
physics_cols = ['Quality', 'Confluence', 'Momentum']
correlations = {}

for col in physics_cols:
    if col in df_trades.columns:
        corr = df_trades[[col, 'NetProfit']].corr().iloc[0, 1]
        correlations[col] = corr
        
        # Calculate averages for winners vs losers
        winner_avg = winners[col].mean() if len(winners) > 0 else 0
        loser_avg = losers[col].mean() if len(losers) > 0 else 0
        separation = winner_avg - loser_avg
        
        print(f"\nüìä {col.upper()}:")
        print(f"   Correlation with NetProfit: {corr:.4f}")
        print(f"   Winners Avg: {winner_avg:.2f}")
        print(f"   Losers Avg: {loser_avg:.2f}")
        print(f"   Separation: {separation:.2f}")
        
        if abs(corr) > 0.15:
            print(f"   ‚úÖ Strong discriminator (|corr| > 0.15)")
        else:
            print(f"   ‚ö†Ô∏è  Weak discriminator (|corr| < 0.15)")

# Find strongest discriminator
strongest_metric = max(correlations, key=lambda k: abs(correlations[k]))
strongest_corr = correlations[strongest_metric]

print(f"\nüéØ STRONGEST DISCRIMINATOR:")
print(f"   {strongest_metric} (r = {strongest_corr:.4f})")

# Calculate potential threshold (25th percentile of winners)
if len(winners) > 0:
    threshold = winners[strongest_metric].quantile(0.25)
    print(f"   Suggested MinThreshold: {threshold:.2f} (25th percentile of winners)")

# ============================================================================
# DAY OF WEEK ANALYSIS
# ============================================================================
print("\n" + "="*80)
print("5M DAY OF WEEK ANALYSIS")
print("="*80)

dow_performance = df_trades.groupby('DayOfWeek').agg({
    'TradeID': 'count',
    'NetProfit': ['sum', 'mean']
}).round(2)

dow_performance.columns = ['Trades', 'Total_PnL', 'Avg_PnL']

dow_winners = df_trades[df_trades['NetProfit'] > 0].groupby('DayOfWeek').size()
dow_wr = (dow_winners / df_trades.groupby('DayOfWeek').size() * 100).round(1)

# Order by standard week order
day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
dow_summary = pd.DataFrame({
    'Trades': dow_performance['Trades'],
    'WR%': dow_wr,
    'Total_PnL': dow_performance['Total_PnL'],
    'Avg_PnL': dow_performance['Avg_PnL']
})
dow_summary = dow_summary.reindex([d for d in day_order if d in dow_summary.index])

print("\nüìä DAY OF WEEK PERFORMANCE:")
print(dow_summary.to_string())

# ============================================================================
# OPTIMIZATION RECOMMENDATIONS
# ============================================================================
print("\n" + "="*80)
print("v3.1_05M OPTIMIZATION RECOMMENDATIONS")
print("="*80)

print("\nüéØ RECOMMENDED FILTERS FOR v3.1_05M:")

# Zone filter
zone_trades_lost = zone_summary.loc[worst_zone_5m, 'Trades']
zone_pct_eliminated = (zone_trades_lost / total_trades * 100)
print(f"\n1. ZONE FILTER:")
print(f"   ‚ùå Avoid: {worst_zone_5m} ({worst_zone_wr_5m:.1f}% WR)")
print(f"   Impact: Eliminates {int(zone_trades_lost)} trades ({zone_pct_eliminated:.1f}%)")
print(f"   Setting: EnableZoneFilter = true, AllowedZones = !{worst_zone_5m}")

# Regime filter
regime_trades_lost = regime_summary.loc[worst_regime_5m, 'Trades']
regime_pct_eliminated = (regime_trades_lost / total_trades * 100)
print(f"\n2. REGIME FILTER:")
print(f"   ‚ùå Avoid: {worst_regime_5m} ({worst_regime_wr_5m:.1f}% WR)")
print(f"   Impact: Eliminates {int(regime_trades_lost)} trades ({regime_pct_eliminated:.1f}%)")
print(f"   Setting: EnableRegimeFilter = true, AllowedRegimes = !{worst_regime_5m}")

# Time filter - show top 3 and bottom 3 hours
top_hours = hourly_summary.nlargest(3, 'WR%')
bottom_hours = hourly_summary.nsmallest(3, 'WR%')

print(f"\n3. TIME FILTER:")
print(f"   ‚≠ê Best Hours: {', '.join(map(str, top_hours.index.tolist()))}")
print(f"      Win Rates: {', '.join([f'{wr:.1f}%' for wr in top_hours['WR%']])}")
print(f"   ‚ùå Worst Hours: {', '.join(map(str, bottom_hours.index.tolist()))}")
print(f"      Win Rates: {', '.join([f'{wr:.1f}%' for wr in bottom_hours['WR%']])}")
print(f"   Setting: EnableTimeFilter = true, TradingStartHour = {top_hours.index[0]}, TradingEndHour = {top_hours.index[-1]}")

# Combined impact estimate
combined_trades_lost = zone_trades_lost + regime_trades_lost
combined_pct = (combined_trades_lost / total_trades * 100)
expected_remaining = total_trades - combined_trades_lost

print(f"\nüìä COMBINED FILTER IMPACT ESTIMATE:")
print(f"   Zone + Regime filters eliminate ~{int(combined_trades_lost)} trades ({combined_pct:.1f}%)")
print(f"   Expected remaining: ~{int(expected_remaining)} trades")
print(f"   Time filter will further reduce (exact impact requires testing)")
print(f"   Target: Similar to 15M v3.1 (97% reduction: 454‚Üí13 trades)")

# ============================================================================
# CROSS-TIMEFRAME SCALABILITY ANALYSIS
# ============================================================================
print("\n" + "="*80)
print("CROSS-TIMEFRAME SCALABILITY ANALYSIS")
print("="*80)

print("\nüìà DEPLOYMENT STRATEGY:")
print(f"   15M Baseline: {ref_15m['trades']} trades / {ref_15m['test_days']} days = {ref_15m['trades']/ref_15m['test_days']:.2f} trades/day")
print(f"   5M Baseline: {total_trades} trades / {test_days} days = {total_trades/test_days:.2f} trades/day")
print(f"   Combined (15M + 5M): {(ref_15m['trades']/ref_15m['test_days'] + total_trades/test_days):.2f} trades/day")

print(f"\nüî¢ SCALABILITY CALCULATION:")
print(f"   Assume optimized 15M: 5 trades / 267 days = 0.019 trades/day")
print(f"   Assume optimized 5M: ~{int(expected_remaining)} trades / {test_days} days = {expected_remaining/test_days:.3f} trades/day")
print(f"   Combined per symbol: ~{0.019 + expected_remaining/test_days:.3f} trades/day")
print(f"   ")
print(f"   √ó 3 timeframes (1M, 5M, 15M): 3x multiplier")
print(f"   √ó 120 symbols: 120x multiplier")
print(f"   ")
print(f"   Total capacity: ~{(0.019 + expected_remaining/test_days) * 3 * 120:.0f} trades/day")
print(f"   Or: ~{(0.019 + expected_remaining/test_days) * 3 * 120 * 267:.0f} trades/year")

print(f"\n‚úÖ STRATEGY VALIDATION:")
print(f"   Low per-timeframe trade count acceptable")
print(f"   Ultra-selective approach (80% WR on 15M) scales via diversification")
print(f"   Multiple timeframes capture different intra-day patterns")
print(f"   120 symbols provide massive parallel opportunities")

# ============================================================================
# SUMMARY
# ============================================================================
print("\n" + "="*80)
print("ANALYSIS COMPLETE - NEXT STEPS")
print("="*80)

print(f"\nüìù SUMMARY:")
print(f"   ‚úÖ 5M baseline analyzed: {total_trades:,} trades, {win_rate:.1f}% WR, PF {profit_factor:.2f}")
print(f"   ‚úÖ Compared to 15M: {trade_ratio:.1f}x more trades, {signal_ratio:.1f}x more signals")
print(f"   ‚úÖ Zone/Regime/Time patterns identified")
print(f"   ‚úÖ Physics correlations calculated")
print(f"   ‚úÖ Optimization recommendations ready")

print(f"\nüéØ NEXT ACTIONS:")
print(f"   1. Create TP_Integrated_EA_Crossover_3_1_05M.mq5")
print(f"      - EnableZoneFilter = true, avoid {worst_zone_5m}")
print(f"      - EnableRegimeFilter = true, avoid {worst_regime_5m}")
print(f"      - EnableTimeFilter = true, optimal hours TBD")
print(f"      - MagicNumber = 300311")
print(f"   ")
print(f"   2. Run v3.1_05M backtest")
print(f"   ")
print(f"   3. Analyze v3.1_05M results")
print(f"      - Compare to v3.0_05M baseline")
print(f"      - Validate filter effectiveness")
print(f"   ")
print(f"   4. Create v3.2_05M with physics thresholds")
print(f"      - Focus on {strongest_metric} (strongest discriminator)")
print(f"      - MinThreshold based on winner analysis")

print("\n" + "="*80)
print("Analysis saved. Ready for v3.1_05M EA creation!")
print("="*80)
